{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction:\n",
    "Using SVM Classifier to classify tumors into Malignant or Benign type, when provided with the tumor's dimensions. In the output we will have probability of tumor of belonging to either Malignant or Benign class.\n",
    "\n",
    "3 parts:\n",
    "\n",
    "1.Data pre-processing and quick analysis\n",
    "\n",
    "2.Building SVM Classifier\n",
    "\n",
    "3.Making Predictions. So let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIT 1: IMPORT DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'C:\\Users\\kshit\\Downloads\\breast_cancer_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0      842302         M       17.990         10.38          122.80     1001.0   \n",
      "1      842517         M       20.570         17.77          132.90     1326.0   \n",
      "2    84300903         M       19.690         21.25          130.00     1203.0   \n",
      "3    84348301         M       11.420         20.38           77.58      386.1   \n",
      "4    84358402         M       20.290         14.34          135.10     1297.0   \n",
      "5      843786         M       12.450         15.70           82.57      477.1   \n",
      "6      844359         M       18.250         19.98          119.60     1040.0   \n",
      "7    84458202         M       13.710         20.83           90.20      577.9   \n",
      "8      844981         M       13.000         21.82           87.50      519.8   \n",
      "9    84501001         M       12.460         24.04           83.97      475.9   \n",
      "10     845636         M       16.020         23.24          102.70      797.8   \n",
      "11   84610002         M       15.780         17.89          103.60      781.0   \n",
      "12     846226         M       19.170         24.80          132.40     1123.0   \n",
      "13     846381         M       15.850         23.95          103.70      782.7   \n",
      "14   84667401         M       13.730         22.61           93.60      578.3   \n",
      "15   84799002         M       14.540         27.54           96.73      658.8   \n",
      "16     848406         M       14.680         20.13           94.74      684.5   \n",
      "17   84862001         M       16.130         20.68          108.10      798.8   \n",
      "18     849014         M       19.810         22.15          130.00     1260.0   \n",
      "19    8510426         B       13.540         14.36           87.46      566.3   \n",
      "20    8510653         B       13.080         15.71           85.63      520.0   \n",
      "21    8510824         B        9.504         12.44           60.34      273.9   \n",
      "22    8511133         M       15.340         14.26          102.50      704.4   \n",
      "23     851509         M       21.160         23.04          137.20     1404.0   \n",
      "24     852552         M       16.650         21.38          110.00      904.6   \n",
      "25     852631         M       17.140         16.40          116.00      912.7   \n",
      "26     852763         M       14.580         21.53           97.41      644.8   \n",
      "27     852781         M       18.610         20.25          122.10     1094.0   \n",
      "28     852973         M       15.300         25.27          102.40      732.4   \n",
      "29     853201         M       17.570         15.05          115.00      955.1   \n",
      "..        ...       ...          ...           ...             ...        ...   \n",
      "539    921362         B        7.691         25.44           48.34      170.4   \n",
      "540    921385         B       11.540         14.44           74.65      402.9   \n",
      "541    921386         B       14.470         24.99           95.81      656.4   \n",
      "542    921644         B       14.740         25.42           94.70      668.6   \n",
      "543    922296         B       13.210         28.06           84.88      538.4   \n",
      "544    922297         B       13.870         20.70           89.77      584.8   \n",
      "545    922576         B       13.620         23.23           87.19      573.2   \n",
      "546    922577         B       10.320         16.35           65.31      324.9   \n",
      "547    922840         B       10.260         16.58           65.85      320.8   \n",
      "548    923169         B        9.683         19.34           61.05      285.7   \n",
      "549    923465         B       10.820         24.21           68.89      361.6   \n",
      "550    923748         B       10.860         21.48           68.51      360.5   \n",
      "551    923780         B       11.130         22.44           71.49      378.4   \n",
      "552    924084         B       12.770         29.43           81.35      507.9   \n",
      "553    924342         B        9.333         21.94           59.01      264.0   \n",
      "554    924632         B       12.880         28.92           82.50      514.3   \n",
      "555    924934         B       10.290         27.61           65.67      321.4   \n",
      "556    924964         B       10.160         19.59           64.73      311.7   \n",
      "557    925236         B        9.423         27.88           59.26      271.3   \n",
      "558    925277         B       14.590         22.68           96.39      657.1   \n",
      "559    925291         B       11.510         23.93           74.52      403.5   \n",
      "560    925292         B       14.050         27.15           91.38      600.4   \n",
      "561    925311         B       11.200         29.37           70.67      386.0   \n",
      "562    925622         M       15.220         30.62          103.40      716.9   \n",
      "563    926125         M       20.920         25.09          143.00     1347.0   \n",
      "564    926424         M       21.560         22.39          142.00     1479.0   \n",
      "565    926682         M       20.130         28.25          131.20     1261.0   \n",
      "566    926954         M       16.600         28.08          108.30      858.1   \n",
      "567    927241         M       20.600         29.33          140.10     1265.0   \n",
      "568     92751         B        7.760         24.54           47.92      181.0   \n",
      "\n",
      "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0            0.11840           0.27760        0.300100             0.147100   \n",
      "1            0.08474           0.07864        0.086900             0.070170   \n",
      "2            0.10960           0.15990        0.197400             0.127900   \n",
      "3            0.14250           0.28390        0.241400             0.105200   \n",
      "4            0.10030           0.13280        0.198000             0.104300   \n",
      "5            0.12780           0.17000        0.157800             0.080890   \n",
      "6            0.09463           0.10900        0.112700             0.074000   \n",
      "7            0.11890           0.16450        0.093660             0.059850   \n",
      "8            0.12730           0.19320        0.185900             0.093530   \n",
      "9            0.11860           0.23960        0.227300             0.085430   \n",
      "10           0.08206           0.06669        0.032990             0.033230   \n",
      "11           0.09710           0.12920        0.099540             0.066060   \n",
      "12           0.09740           0.24580        0.206500             0.111800   \n",
      "13           0.08401           0.10020        0.099380             0.053640   \n",
      "14           0.11310           0.22930        0.212800             0.080250   \n",
      "15           0.11390           0.15950        0.163900             0.073640   \n",
      "16           0.09867           0.07200        0.073950             0.052590   \n",
      "17           0.11700           0.20220        0.172200             0.102800   \n",
      "18           0.09831           0.10270        0.147900             0.094980   \n",
      "19           0.09779           0.08129        0.066640             0.047810   \n",
      "20           0.10750           0.12700        0.045680             0.031100   \n",
      "21           0.10240           0.06492        0.029560             0.020760   \n",
      "22           0.10730           0.21350        0.207700             0.097560   \n",
      "23           0.09428           0.10220        0.109700             0.086320   \n",
      "24           0.11210           0.14570        0.152500             0.091700   \n",
      "25           0.11860           0.22760        0.222900             0.140100   \n",
      "26           0.10540           0.18680        0.142500             0.087830   \n",
      "27           0.09440           0.10660        0.149000             0.077310   \n",
      "28           0.10820           0.16970        0.168300             0.087510   \n",
      "29           0.09847           0.11570        0.098750             0.079530   \n",
      "..               ...               ...             ...                  ...   \n",
      "539          0.08668           0.11990        0.092520             0.013640   \n",
      "540          0.09984           0.11200        0.067370             0.025940   \n",
      "541          0.08837           0.12300        0.100900             0.038900   \n",
      "542          0.08275           0.07214        0.041050             0.030270   \n",
      "543          0.08671           0.06877        0.029870             0.032750   \n",
      "544          0.09578           0.10180        0.036880             0.023690   \n",
      "545          0.09246           0.06747        0.029740             0.024430   \n",
      "546          0.09434           0.04994        0.010120             0.005495   \n",
      "547          0.08877           0.08066        0.043580             0.024380   \n",
      "548          0.08491           0.05030        0.023370             0.009615   \n",
      "549          0.08192           0.06602        0.015480             0.008160   \n",
      "550          0.07431           0.04227        0.000000             0.000000   \n",
      "551          0.09566           0.08194        0.048240             0.022570   \n",
      "552          0.08276           0.04234        0.019970             0.014990   \n",
      "553          0.09240           0.05605        0.039960             0.012820   \n",
      "554          0.08123           0.05824        0.061950             0.023430   \n",
      "555          0.09030           0.07658        0.059990             0.027380   \n",
      "556          0.10030           0.07504        0.005025             0.011160   \n",
      "557          0.08123           0.04971        0.000000             0.000000   \n",
      "558          0.08473           0.13300        0.102900             0.037360   \n",
      "559          0.09261           0.10210        0.111200             0.041050   \n",
      "560          0.09929           0.11260        0.044620             0.043040   \n",
      "561          0.07449           0.03558        0.000000             0.000000   \n",
      "562          0.10480           0.20870        0.255000             0.094290   \n",
      "563          0.10990           0.22360        0.317400             0.147400   \n",
      "564          0.11100           0.11590        0.243900             0.138900   \n",
      "565          0.09780           0.10340        0.144000             0.097910   \n",
      "566          0.08455           0.10230        0.092510             0.053020   \n",
      "567          0.11780           0.27700        0.351400             0.152000   \n",
      "568          0.05263           0.04362        0.000000             0.000000   \n",
      "\n",
      "     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
      "0    ...        25.380          17.33           184.60      2019.0   \n",
      "1    ...        24.990          23.41           158.80      1956.0   \n",
      "2    ...        23.570          25.53           152.50      1709.0   \n",
      "3    ...        14.910          26.50            98.87       567.7   \n",
      "4    ...        22.540          16.67           152.20      1575.0   \n",
      "5    ...        15.470          23.75           103.40       741.6   \n",
      "6    ...        22.880          27.66           153.20      1606.0   \n",
      "7    ...        17.060          28.14           110.60       897.0   \n",
      "8    ...        15.490          30.73           106.20       739.3   \n",
      "9    ...        15.090          40.68            97.65       711.4   \n",
      "10   ...        19.190          33.88           123.80      1150.0   \n",
      "11   ...        20.420          27.28           136.50      1299.0   \n",
      "12   ...        20.960          29.94           151.70      1332.0   \n",
      "13   ...        16.840          27.66           112.00       876.5   \n",
      "14   ...        15.030          32.01           108.80       697.7   \n",
      "15   ...        17.460          37.13           124.10       943.2   \n",
      "16   ...        19.070          30.88           123.40      1138.0   \n",
      "17   ...        20.960          31.48           136.80      1315.0   \n",
      "18   ...        27.320          30.88           186.80      2398.0   \n",
      "19   ...        15.110          19.26            99.70       711.2   \n",
      "20   ...        14.500          20.49            96.09       630.5   \n",
      "21   ...        10.230          15.66            65.13       314.9   \n",
      "22   ...        18.070          19.08           125.10       980.9   \n",
      "23   ...        29.170          35.59           188.00      2615.0   \n",
      "24   ...        26.460          31.56           177.00      2215.0   \n",
      "25   ...        22.250          21.40           152.40      1461.0   \n",
      "26   ...        17.620          33.21           122.40       896.9   \n",
      "27   ...        21.310          27.26           139.90      1403.0   \n",
      "28   ...        20.270          36.71           149.30      1269.0   \n",
      "29   ...        20.010          19.52           134.90      1227.0   \n",
      "..   ...           ...            ...              ...         ...   \n",
      "539  ...         8.678          31.89            54.49       223.6   \n",
      "540  ...        12.260          19.68            78.78       457.8   \n",
      "541  ...        16.220          31.73           113.50       808.9   \n",
      "542  ...        16.510          32.29           107.40       826.4   \n",
      "543  ...        14.370          37.17            92.48       629.6   \n",
      "544  ...        15.050          24.75            99.17       688.6   \n",
      "545  ...        15.350          29.09            97.58       729.8   \n",
      "546  ...        11.250          21.77            71.12       384.9   \n",
      "547  ...        10.830          22.04            71.08       357.4   \n",
      "548  ...        10.930          25.59            69.10       364.2   \n",
      "549  ...        13.030          31.45            83.90       505.6   \n",
      "550  ...        11.660          24.77            74.08       412.3   \n",
      "551  ...        12.020          28.26            77.80       436.6   \n",
      "552  ...        13.870          36.00            88.10       594.7   \n",
      "553  ...         9.845          25.05            62.86       295.8   \n",
      "554  ...        13.890          35.74            88.84       595.7   \n",
      "555  ...        10.840          34.91            69.57       357.6   \n",
      "556  ...        10.650          22.88            67.88       347.3   \n",
      "557  ...        10.490          34.24            66.50       330.6   \n",
      "558  ...        15.480          27.27           105.90       733.5   \n",
      "559  ...        12.480          37.16            82.28       474.2   \n",
      "560  ...        15.300          33.17           100.20       706.7   \n",
      "561  ...        11.920          38.30            75.19       439.6   \n",
      "562  ...        17.520          42.79           128.70       915.0   \n",
      "563  ...        24.290          29.41           179.10      1819.0   \n",
      "564  ...        25.450          26.40           166.10      2027.0   \n",
      "565  ...        23.690          38.25           155.00      1731.0   \n",
      "566  ...        18.980          34.12           126.70      1124.0   \n",
      "567  ...        25.740          39.42           184.60      1821.0   \n",
      "568  ...         9.456          30.37            59.16       268.6   \n",
      "\n",
      "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0             0.16220            0.66560          0.71190   \n",
      "1             0.12380            0.18660          0.24160   \n",
      "2             0.14440            0.42450          0.45040   \n",
      "3             0.20980            0.86630          0.68690   \n",
      "4             0.13740            0.20500          0.40000   \n",
      "5             0.17910            0.52490          0.53550   \n",
      "6             0.14420            0.25760          0.37840   \n",
      "7             0.16540            0.36820          0.26780   \n",
      "8             0.17030            0.54010          0.53900   \n",
      "9             0.18530            1.05800          1.10500   \n",
      "10            0.11810            0.15510          0.14590   \n",
      "11            0.13960            0.56090          0.39650   \n",
      "12            0.10370            0.39030          0.36390   \n",
      "13            0.11310            0.19240          0.23220   \n",
      "14            0.16510            0.77250          0.69430   \n",
      "15            0.16780            0.65770          0.70260   \n",
      "16            0.14640            0.18710          0.29140   \n",
      "17            0.17890            0.42330          0.47840   \n",
      "18            0.15120            0.31500          0.53720   \n",
      "19            0.14400            0.17730          0.23900   \n",
      "20            0.13120            0.27760          0.18900   \n",
      "21            0.13240            0.11480          0.08867   \n",
      "22            0.13900            0.59540          0.63050   \n",
      "23            0.14010            0.26000          0.31550   \n",
      "24            0.18050            0.35780          0.46950   \n",
      "25            0.15450            0.39490          0.38530   \n",
      "26            0.15250            0.66430          0.55390   \n",
      "27            0.13380            0.21170          0.34460   \n",
      "28            0.16410            0.61100          0.63350   \n",
      "29            0.12550            0.28120          0.24890   \n",
      "..                ...                ...              ...   \n",
      "539           0.15960            0.30640          0.33930   \n",
      "540           0.13450            0.21180          0.17970   \n",
      "541           0.13400            0.42020          0.40400   \n",
      "542           0.10600            0.13760          0.16110   \n",
      "543           0.10720            0.13810          0.10620   \n",
      "544           0.12640            0.20370          0.13770   \n",
      "545           0.12160            0.15170          0.10490   \n",
      "546           0.12850            0.08842          0.04384   \n",
      "547           0.14610            0.22460          0.17830   \n",
      "548           0.11990            0.09546          0.09350   \n",
      "549           0.12040            0.16330          0.06194   \n",
      "550           0.10010            0.07348          0.00000   \n",
      "551           0.10870            0.17820          0.15640   \n",
      "552           0.12340            0.10640          0.08653   \n",
      "553           0.11030            0.08298          0.07993   \n",
      "554           0.12270            0.16200          0.24390   \n",
      "555           0.13840            0.17100          0.20000   \n",
      "556           0.12650            0.12000          0.01005   \n",
      "557           0.10730            0.07158          0.00000   \n",
      "558           0.10260            0.31710          0.36620   \n",
      "559           0.12980            0.25170          0.36300   \n",
      "560           0.12410            0.22640          0.13260   \n",
      "561           0.09267            0.05494          0.00000   \n",
      "562           0.14170            0.79170          1.17000   \n",
      "563           0.14070            0.41860          0.65990   \n",
      "564           0.14100            0.21130          0.41070   \n",
      "565           0.11660            0.19220          0.32150   \n",
      "566           0.11390            0.30940          0.34030   \n",
      "567           0.16500            0.86810          0.93870   \n",
      "568           0.08996            0.06444          0.00000   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
      "0                 0.26540          0.4601                  0.11890  \n",
      "1                 0.18600          0.2750                  0.08902  \n",
      "2                 0.24300          0.3613                  0.08758  \n",
      "3                 0.25750          0.6638                  0.17300  \n",
      "4                 0.16250          0.2364                  0.07678  \n",
      "5                 0.17410          0.3985                  0.12440  \n",
      "6                 0.19320          0.3063                  0.08368  \n",
      "7                 0.15560          0.3196                  0.11510  \n",
      "8                 0.20600          0.4378                  0.10720  \n",
      "9                 0.22100          0.4366                  0.20750  \n",
      "10                0.09975          0.2948                  0.08452  \n",
      "11                0.18100          0.3792                  0.10480  \n",
      "12                0.17670          0.3176                  0.10230  \n",
      "13                0.11190          0.2809                  0.06287  \n",
      "14                0.22080          0.3596                  0.14310  \n",
      "15                0.17120          0.4218                  0.13410  \n",
      "16                0.16090          0.3029                  0.08216  \n",
      "17                0.20730          0.3706                  0.11420  \n",
      "18                0.23880          0.2768                  0.07615  \n",
      "19                0.12880          0.2977                  0.07259  \n",
      "20                0.07283          0.3184                  0.08183  \n",
      "21                0.06227          0.2450                  0.07773  \n",
      "22                0.23930          0.4667                  0.09946  \n",
      "23                0.20090          0.2822                  0.07526  \n",
      "24                0.20950          0.3613                  0.09564  \n",
      "25                0.25500          0.4066                  0.10590  \n",
      "26                0.27010          0.4264                  0.12750  \n",
      "27                0.14900          0.2341                  0.07421  \n",
      "28                0.20240          0.4027                  0.09876  \n",
      "29                0.14560          0.2756                  0.07919  \n",
      "..                    ...             ...                      ...  \n",
      "539               0.05000          0.2790                  0.10660  \n",
      "540               0.06918          0.2329                  0.08134  \n",
      "541               0.12050          0.3187                  0.10230  \n",
      "542               0.10950          0.2722                  0.06956  \n",
      "543               0.07958          0.2473                  0.06443  \n",
      "544               0.06845          0.2249                  0.08492  \n",
      "545               0.07174          0.2642                  0.06953  \n",
      "546               0.02381          0.2681                  0.07399  \n",
      "547               0.08333          0.2691                  0.09479  \n",
      "548               0.03846          0.2552                  0.07920  \n",
      "549               0.03264          0.3059                  0.07626  \n",
      "550               0.00000          0.2458                  0.06592  \n",
      "551               0.06413          0.3169                  0.08032  \n",
      "552               0.06498          0.2407                  0.06484  \n",
      "553               0.02564          0.2435                  0.07393  \n",
      "554               0.06493          0.2372                  0.07242  \n",
      "555               0.09127          0.2226                  0.08283  \n",
      "556               0.02232          0.2262                  0.06742  \n",
      "557               0.00000          0.2475                  0.06969  \n",
      "558               0.11050          0.2258                  0.08004  \n",
      "559               0.09653          0.2112                  0.08732  \n",
      "560               0.10480          0.2250                  0.08321  \n",
      "561               0.00000          0.1566                  0.05905  \n",
      "562               0.23560          0.4089                  0.14090  \n",
      "563               0.25420          0.2929                  0.09873  \n",
      "564               0.22160          0.2060                  0.07115  \n",
      "565               0.16280          0.2572                  0.06637  \n",
      "566               0.14180          0.2218                  0.07820  \n",
      "567               0.26500          0.4087                  0.12400  \n",
      "568               0.00000          0.2871                  0.07039  \n",
      "\n",
      "[569 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIT 2:DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  5.690000e+02   569.000000    569.000000      569.000000   569.000000   \n",
       "mean   3.037183e+07    14.127292     19.289649       91.969033   654.889104   \n",
       "std    1.250206e+08     3.524049      4.301036       24.298981   351.914129   \n",
       "min    8.670000e+03     6.981000      9.710000       43.790000   143.500000   \n",
       "25%    8.692180e+05    11.700000     16.170000       75.170000   420.300000   \n",
       "50%    9.060240e+05    13.370000     18.840000       86.240000   551.100000   \n",
       "75%    8.813129e+06    15.780000     21.800000      104.100000   782.700000   \n",
       "max    9.113205e+08    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "count     569.000000  ...    569.000000     569.000000       569.000000   \n",
       "mean        0.181162  ...     16.269190      25.677223       107.261213   \n",
       "std         0.027414  ...      4.833242       6.146258        33.602542   \n",
       "min         0.106000  ...      7.930000      12.020000        50.410000   \n",
       "25%         0.161900  ...     13.010000      21.080000        84.110000   \n",
       "50%         0.179200  ...     14.970000      25.410000        97.660000   \n",
       "75%         0.195700  ...     18.790000      29.720000       125.400000   \n",
       "max         0.304000  ...     36.040000      49.540000       251.200000   \n",
       "\n",
       "        area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "count   569.000000        569.000000         569.000000       569.000000   \n",
       "mean    880.583128          0.132369           0.254265         0.272188   \n",
       "std     569.356993          0.022832           0.157336         0.208624   \n",
       "min     185.200000          0.071170           0.027290         0.000000   \n",
       "25%     515.300000          0.116600           0.147200         0.114500   \n",
       "50%     686.500000          0.131300           0.211900         0.226700   \n",
       "75%    1084.000000          0.146000           0.339100         0.382900   \n",
       "max    4254.000000          0.222600           1.058000         1.252000   \n",
       "\n",
       "       concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "count            569.000000      569.000000               569.000000  \n",
       "mean               0.114606        0.290076                 0.083946  \n",
       "std                0.065732        0.061867                 0.018061  \n",
       "min                0.000000        0.156500                 0.055040  \n",
       "25%                0.064930        0.250400                 0.071460  \n",
       "50%                0.099930        0.282200                 0.080040  \n",
       "75%                0.161400        0.317900                 0.092080  \n",
       "max                0.291000        0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Specs          Score\n",
      "23       area_worst  112598.431564\n",
      "3         area_mean   53991.655924\n",
      "13          area_se    8758.504705\n",
      "22  perimeter_worst    3665.035416\n",
      "2    perimeter_mean    2011.102864\n",
      "20     radius_worst     491.689157\n",
      "0       radius_mean     266.104917\n",
      "12     perimeter_se     250.571896\n",
      "21    texture_worst     174.449400\n",
      "1      texture_mean      93.897508\n"
     ]
    }
   ],
   "source": [
    "##FEATURE SELECTION::\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "X1= dataset.iloc[: , 2:32]\n",
    "y= dataset.iloc[:, 1]\n",
    "\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X1,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X1.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>area_se</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>texture_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>153.40</td>\n",
       "      <td>184.60</td>\n",
       "      <td>122.80</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.99</td>\n",
       "      <td>8.589</td>\n",
       "      <td>17.33</td>\n",
       "      <td>10.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>74.08</td>\n",
       "      <td>158.80</td>\n",
       "      <td>132.90</td>\n",
       "      <td>24.99</td>\n",
       "      <td>20.57</td>\n",
       "      <td>3.398</td>\n",
       "      <td>23.41</td>\n",
       "      <td>17.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>94.03</td>\n",
       "      <td>152.50</td>\n",
       "      <td>130.00</td>\n",
       "      <td>23.57</td>\n",
       "      <td>19.69</td>\n",
       "      <td>4.585</td>\n",
       "      <td>25.53</td>\n",
       "      <td>21.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>567.7</td>\n",
       "      <td>386.1</td>\n",
       "      <td>27.23</td>\n",
       "      <td>98.87</td>\n",
       "      <td>77.58</td>\n",
       "      <td>14.91</td>\n",
       "      <td>11.42</td>\n",
       "      <td>3.445</td>\n",
       "      <td>26.50</td>\n",
       "      <td>20.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>94.44</td>\n",
       "      <td>152.20</td>\n",
       "      <td>135.10</td>\n",
       "      <td>22.54</td>\n",
       "      <td>20.29</td>\n",
       "      <td>5.438</td>\n",
       "      <td>16.67</td>\n",
       "      <td>14.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  area_worst  area_mean  area_se  perimeter_worst  perimeter_mean  \\\n",
       "0    842302      2019.0     1001.0   153.40           184.60          122.80   \n",
       "1    842517      1956.0     1326.0    74.08           158.80          132.90   \n",
       "2  84300903      1709.0     1203.0    94.03           152.50          130.00   \n",
       "3  84348301       567.7      386.1    27.23            98.87           77.58   \n",
       "4  84358402      1575.0     1297.0    94.44           152.20          135.10   \n",
       "\n",
       "   radius_worst  radius_mean  perimeter_se  texture_worst  texture_mean  \n",
       "0         25.38        17.99         8.589          17.33         10.38  \n",
       "1         24.99        20.57         3.398          23.41         17.77  \n",
       "2         23.57        19.69         4.585          25.53         21.25  \n",
       "3         14.91        11.42         3.445          26.50         20.38  \n",
       "4         22.54        20.29         5.438          16.67         14.34  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['id','area_worst','area_mean','area_se','perimeter_worst','perimeter_mean','radius_worst',\n",
    "            'radius_mean','perimeter_se','texture_worst','texture_mean']\n",
    "X= dataset[features]\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENCODING THE TARGET CLASS FOR MALIGNANT AND BENIGN AS 0 AND 1.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_y = LabelEncoder()\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "z= y.reshape(-1,1)\n",
    "y=z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITING THE DATASET\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X=StandardScaler()\n",
    "X_train= sc_X.fit_transform(X_train)\n",
    "X_test= sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIT 3: APLYING THE SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the SVM classifier to training set\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIT 4: EVALUATING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1\n",
      " 0 1 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 1 0 1 1 0 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "#predicting the test results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.00699300699301%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True)\n",
    "#calcualting accuracy of the model\n",
    "accuracy = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
    "print(\"Accuracy: \"+ str(accuracy*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.905660</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>0.925052</td>\n",
       "      <td>0.929527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.923913</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>0.932545</td>\n",
       "      <td>0.930553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.965909</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>0.919318</td>\n",
       "      <td>0.930070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.93007</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1  accuracy   macro avg  weighted avg\n",
       "f1-score    0.944444   0.905660   0.93007    0.925052      0.929527\n",
       "precision   0.923913   0.941176   0.93007    0.932545      0.930553\n",
       "recall      0.965909   0.872727   0.93007    0.919318      0.930070\n",
       "support    88.000000  55.000000   0.93007  143.000000    143.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report_dict = classification_report(y_test, y_pred, output_dict=True)\n",
    "pd.DataFrame(report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIT 5: IMPROVING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.937, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.944, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=0.1, gamma=1, kernel=linear, score=0.965, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.937, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.944, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=0.1, gamma=0.1, kernel=linear, score=0.965, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.937, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.944, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=0.1, gamma=0.01, kernel=linear, score=0.965, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.937, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.944, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=0.1, gamma=0.001, kernel=linear, score=0.965, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.909, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=linear .....................................\n",
      "[CV] ......... C=1, gamma=1, kernel=linear, score=0.979, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.909, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=linear ...................................\n",
      "[CV] ....... C=1, gamma=0.1, kernel=linear, score=0.979, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.909, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.979, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.909, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.979, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.902, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=linear ....................................\n",
      "[CV] ........ C=10, gamma=1, kernel=linear, score=0.979, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.902, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=linear ..................................\n",
      "[CV] ...... C=10, gamma=0.1, kernel=linear, score=0.979, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.902, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.979, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.902, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.958, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.979, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=100, gamma=1, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=100, gamma=1, kernel=linear, score=0.951, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=linear ...................................\n",
      "[CV] ....... C=100, gamma=1, kernel=linear, score=0.986, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.951, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=linear .................................\n",
      "[CV] ..... C=100, gamma=0.1, kernel=linear, score=0.986, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.951, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=linear ................................\n",
      "[CV] .... C=100, gamma=0.01, kernel=linear, score=0.986, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.951, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=linear ...............................\n",
      "[CV] ... C=100, gamma=0.001, kernel=linear, score=0.986, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:    0.1s finished\n",
      "C:\\Users\\kshit\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Applying Grid Search to find the best model and the best parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.1,1,10,100], 'gamma': [1,0.1,0.01,0.001],'kernel':['linear']}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, refit=True, verbose=4)\n",
    "grid_search = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm= confusion_matrix(y_test,grid_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.8041958041958%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, annot=True)\n",
    "accuracy = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
    "print(\"Accuracy: \"+ str(accuracy*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.955031</td>\n",
       "      <td>0.957716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.963022</td>\n",
       "      <td>0.959014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.988636</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.948864</td>\n",
       "      <td>0.958042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>88.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0          1  accuracy   macro avg  weighted avg\n",
       "f1-score    0.966667   0.943396  0.958042    0.955031      0.957716\n",
       "precision   0.945652   0.980392  0.958042    0.963022      0.959014\n",
       "recall      0.988636   0.909091  0.958042    0.948864      0.958042\n",
       "support    88.000000  55.000000  0.958042  143.000000    143.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_dict = classification_report(y_test, grid_predictions, output_dict=True)\n",
    "pd.DataFrame(report_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
